# Nginx configuration for WebRTC/WebSocket load balancing with sticky sessions
# This configuration enables horizontal scaling of the backend

# Upstream backend servers
# Add all your backend server instances here
upstream backend_api {
    # Use IP hash for sticky sessions based on client IP
    # This ensures clients always hit the same backend server
    ip_hash;
    
    # Backend server instances
    # Replace with your actual server IPs and ports
    server backend1.example.com:3000;
    server backend2.example.com:3000;
    server backend3.example.com:3000;
    
    # Optional: Weight-based load balancing
    # server backend1.example.com:3000 weight=3;
    # server backend2.example.com:3000 weight=2;
    # server backend3.example.com:3000 weight=1;
    
    # Health check (requires nginx-plus or open-source with health check module)
    # health_check interval=10s fails=3 passes=2;
}

# Upstream WebSocket/Socket.io servers
# Sticky sessions are critical for WebSocket connections
upstream backend_websocket {
    # Use IP hash for sticky sessions
    # This ensures WebSocket connections stay on the same server
    ip_hash;
    
    # Backend server instances
    server backend1.example.com:3000;
    server backend2.example.com:3000;
    server backend3.example.com:3000;
    
    # Alternative: Use consistent hash based on room ID (requires lua or nginx-plus)
    # This is better for WebRTC as all users in a room go to same server
}

# HTTP server (API and static files)
server {
    listen 80;
    listen [::]:80;
    server_name api.example.com;
    
    # Redirect HTTP to HTTPS
    return 301 https://$server_name$request_uri;
}

# HTTPS server
server {
    listen 443 ssl http2;
    listen [::]:443 ssl http2;
    server_name api.example.com;
    
    # SSL configuration
    ssl_certificate /path/to/ssl/cert.pem;
    ssl_certificate_key /path/to/ssl/key.pem;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers HIGH:!aNULL:!MD5;
    ssl_prefer_server_ciphers on;
    
    # Security headers
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-XSS-Protection "1; mode=block" always;
    
    # Client body size (for file uploads)
    client_max_body_size 10M;
    
    # Timeouts
    proxy_connect_timeout 60s;
    proxy_send_timeout 60s;
    proxy_read_timeout 60s;
    
    # API endpoints - load balanced
    location /api/ {
        proxy_pass http://backend_api;
        proxy_http_version 1.1;
        
        # Headers
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # Buffering
        proxy_buffering off;
        proxy_request_buffering off;
    }
    
    # Health check endpoints (no load balancing needed)
    location /health {
        proxy_pass http://backend_api;
        proxy_http_version 1.1;
        proxy_set_header Host $host;
        access_log off;  # Don't log health checks
    }
    
    location /health/live {
        proxy_pass http://backend_api;
        proxy_http_version 1.1;
        proxy_set_header Host $host;
        access_log off;
    }
    
    location /health/ready {
        proxy_pass http://backend_api;
        proxy_http_version 1.1;
        proxy_set_header Host $host;
        access_log off;
    }
    
    # Prometheus metrics
    location /metrics {
        # Optional: Add IP whitelist for security
        # allow 10.0.0.0/8;  # Internal network
        # deny all;
        
        proxy_pass http://backend_api;
        proxy_http_version 1.1;
        proxy_set_header Host $host;
    }
    
    # WebSocket/Socket.io endpoint - CRITICAL: Use sticky sessions
    location /socket {
        proxy_pass http://backend_websocket;
        proxy_http_version 1.1;
        
        # WebSocket upgrade headers
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        
        # Standard headers
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # WebSocket specific settings
        proxy_buffering off;
        proxy_cache off;
        proxy_read_timeout 86400s;  # 24 hours (WebSocket can be long-lived)
        proxy_send_timeout 86400s;
        
        # Increase buffer sizes for WebSocket
        proxy_buffer_size 4k;
        proxy_buffers 8 4k;
    }
    
    # Static files (if serving frontend from Nginx)
    location / {
        root /var/www/html;
        try_files $uri $uri/ /index.html;
        expires 1y;
        add_header Cache-Control "public, immutable";
    }
}

# Separate server block for WebRTC media (optional)
# WebRTC uses UDP, but signaling and some transports use TCP
# For pure WebRTC media traffic, you might want a separate configuration
server {
    listen 30000-30100 udp;
    
    # Note: UDP load balancing is more complex
    # Consider using a specialized load balancer or service mesh
    # For now, WebRTC media goes directly to backend servers
    # The load balancing here is mainly for signaling (WebSocket/TCP)
}

# Rate limiting configuration
limit_req_zone $binary_remote_addr zone=api_limit:10m rate=100r/s;
limit_req_zone $binary_remote_addr zone=ws_limit:10m rate=10r/s;

# Apply rate limiting
server {
    # ... (inside the HTTPS server block)
    location /api/ {
        limit_req zone=api_limit burst=20 nodelay;
        # ... rest of config
    }
    
    location /socket {
        limit_req zone=ws_limit burst=5 nodelay;
        # ... rest of config
    }
}

# Logging
access_log /var/log/nginx/access.log;
error_log /var/log/nginx/error.log warn;

# Gzip compression
gzip on;
gzip_vary on;
gzip_min_length 1024;
gzip_types text/plain text/css text/xml text/javascript application/json application/javascript application/xml+rss;

